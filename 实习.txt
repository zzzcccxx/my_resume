英语口语考试评分项目
项目描述：通过使用深度学习算法，搭建端到端系统。实现输入为学生作答的口语考试答案，输出为学生的考试分数。
责任描述：1、对历史模型进行改进，历史模型采用pipeline形式，先训练由学生作答到给出人工评语（主语缺失、谓语形式错误等），再通过人工评语得到最终得分。首先将人工评语从中文改成更专业的英文人工评语；使用“[cls]问题[sep]学生作答[sep]评语[sep]”和“[cls]答案[sep]学生作答[sep]评语[sep]”来替换只使用评语作为输入；再通过历史数据训练基底模型，并在各省份的定标集上进行finetune。2、使用端到端的系统完成口语考试的评分，在huggingface上调研适合的模型，使用“[cls]答案[sep]学生作答”作为模型的输入，直接输出考试得分。使用数据增强的方法扩充数据，采用bert的mask方法对正确答案进行mask操作以降低过拟合，并在集群上进行训练。
工作结果：1、历史模型改进后有提升但不明显，在 finetune 前改进前相关度 0.830，改进后为 0.838。2、端到端系统改进后的模型在 finetune 前，bert-large 的相关性从 0.866 到 0.877，albert-large 从0.887 到 0.891，roberta-large 从 0.868 到 0.876。结果表明端到端系统相关性更高，且经过数据增强后相关性有提升。



“贴吧文本关系抽取”项目
项目描述：通过深度学习算法对百度贴吧文本中的主体、客体以及他们之间的关系进行学习，从而实现对未见过的句子进行三元组关系抽取。详细步骤已上传博客：https://blog.csdn.net/weixin_49327481/article/details/128092238?spm=1001.2014.3001.5502
责任描述：1、自定义 Dataset 函数实现对数据的批量提取，方便后续训练。2、使用 transformers库中 BertTokenizerFast 模块对文本序列进行中文分词，返回分词后文字 id 值和偏移量，从而解决在输入文本中的中英文混用情况时分词不可逆问题。3、对预测值的损失设置不同的平衡权重系数，避免数据不均衡带来的训练问题。4、在预测主体时利用自注意力机制来增强上下文语义信息，提高主体识别准确度。5、在 kaggle 云服务器上使用 GPU 加速网络模型的训练。
工作结果：1、对预测出来的损失值使用不同的权重系数后，f1 分值从 0.27 提升至 0.62。2、通过分词时的偏移量信息可以正常返回原文中的位置。



“商品评价实体情感识别”项目
项目描述：通过深度学习算法，对商品评价进行分析，得到评价中的实体位置和实体对应的情感分析(好评/差评)。详细步骤已上传博客：https://blog.csdn.net/weixin_49327481/article/details/127578363?spm=1001.2014.3001.5502
责任描述：1、对训练样本进行预处理，形成统一格式。2、自定义 dataset 类来进行数据的批量读取。3、使用 BERT 和 Bi-LSTM 网络对实体位置进行预测，后接上 CRF 层来进行校正。4、模型采用分块思想进行训练，先要得出实体的准确位置，再通过准确位置对情感进行预测，故调高实体预测部分的 loss 权重。5、在进行商品情感预测时，将句子向量和实体附近的特征进行拼接后输入到 selfattention 层来提取整个句子的情感特征。
工作结果：1、实体位置预测部分的 loss 权重不调高时，在训练集上的 f1 分值为 0.8 左右，验证集上f1 值为 0.7 左右，调高时效果虽有提升但很小。2、将 bert 参数都设置为可学习的后，在训练集上 f1分值为 0.95 左右，验证集上为 0.8 左右。


“基于大模型微调商品评价实体情感识别”项目
项目描述：通过使用上述数据集，对chatglm-6b大语言模型进行微调，实现对商品评价的实体位置和情感的预测，详细步骤已上传github：https://github.com/zzzcccxx/goods_glm
主要技术：pytorch + P-tuningv2 + ChatGLM_6b + 服务器训练
责任描述：1、对训练样本进行预处理，生成chatglm模型的输入形式，得到训练数据集和验证数据集。2、通过脚本找到微调训练数据中的输入最大值，更改原模型最大输入长度和输出长度，更改p-tuning词向量个数以适配大模型对下游任务的微调。3、对大模型进行微调，得到ptuning的表示，来得到新的模型权重。4、由于任务特殊性，无法使用原模型的bleu-4和rouge-1/2作为评估指标，故自写评估脚本，当模型输出与答案完全一致时为正确，否则为错误，来计算准确率。
工作结果：1、使用，原模型ptuning128大小时，模型在测试集上准确率acc=0.777，相关性corr=0.858。在使用ptuning64时，模型acc=0.766，corr=0.851，训练时间上ptuning64时训练时间30分钟，当为128训练时间33分钟。2、在模型训练时，若使用quantization来做量化，则训练时间由30分钟增加为60分钟，显存由14G降为3G。



运动想象脑电信号分类项目
项目描述：通过使用深度学习算法，搭建端到端系统。实现输入为脑电信号，输出运动想象的类别。
工作描述：1、使用 EEGLAB 工具箱对脑电数据进行读取和预处理。2、设计深度学习网络模型，采用时空频三条路来进行模型的训练（利用短时傅里叶变换得到脑电信号的时频图、利用 EEGLAB 工具箱生成脑电地形图、再叠加原始信号）。3、采用将同种类别的脑电信号进行随机权重的加权平均来扩充训练样本数量。4、调研深度学习分类算法，在公开脑电数据集 BCIIV2a 上进行基底模型训练。4、在自己采集的数据集上进行网络的 finetune。


申请号或专利号：202310309411.8
一种基于多头注意力的多维运动想象脑电信号分类方法

